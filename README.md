<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
</head>
<body>
  <img src="./docs/banner.png"></img>
  <h1>ğŸ›¸ ONTBO - Cognitive Context API for AI Agents</h1>
  <p style="text-align: center;"><strong>Make AI understand.</strong></p>
  <p style="text-align: center;">ğŸ‘‰ Cognitive Context API for your AI Agents</p>
  <p style="text-align: center;">ğŸ¤– <a href="https://api.ontbo.com">https://api.ontbo.com</a></p>
  <p style="text-align: center;"><em>Doc : <a href="./docs/datasheet.pdf">here</a></em></p>

  <div>
    <h2>âš¡ Research Insights - Why you Win ?</h2>
    <table>
      <tr>
        <th><i>Metric</i></th>
        <th><i>ONTBO</i></th>
        <th><i>SoTA</i></th>
      </tr>
      <tr>
        <td><i>Recall context</i></td>
        <td><b>ğŸ”¥ 91%</b></td>
        <td>70%</td>
      </tr>
      <tr>
        <td><i>Token cost</i></td>
        <td><b>ğŸ’¸ -95%</b></td>
        <td>Full-data retrieval</td>
      </tr>
      <tr>
        <td><i>Latency</i></td>
        <td><b>âš¡ 40 ms (P50)</b></td>
        <td>&gt;200 ms</td>
      </tr>
      <tr>
        <td><i>Model creation speed</i></td>
        <td><b>ğŸš€ +200%</b></td>
        <td>Baseline</td>
      </tr>
    </table>
    <p>ğŸ”„ <b>4 retrieval modes</b>: best-performance, chain-of-thought, balanced, low-latency<br>
    âœ”ï¸ pick precision/latency/cost tradeoffs per request</p>
  </div>

  <div>
    <h2>ğŸ“– Introduction</h2>
    <p>If your assistants hallucinate, token bills spike, and user context lives in 12 different silos â€“ <strong>ONTBO fixes that.</strong></p>
    <p>Plug a <b>cognitive layer</b> in front of your LLMs/Agents and stop duct-taping prompt engineering.<br>
    Your agents become sharper, faster, and cheaper.</p>
    <p><strong>Memory stores. Context understands.</strong></p>
  </div>

  <div>
    <h2>ğŸš€ What is ONTBO?</h2>
    <p style="text-align: center;">ğŸ¤– <a href="https://api.ontbo.com">https://api.ontbo.com</a></p>
    <p>ONTBO is an <b>API that normalizes and structures user historic data</b> into a dynamic, reasoning-ready context layer to improve AI agent responses.<br>
    From <b>passive tools</b> to <b>proactive partners</b>, we build APIs that <b>understand, adapt, and truly work with you.</b></p>
  </div>

  <div>
    <h2>ğŸ§© Main Features</h2>
    <ul>
      <li><strong>Context Layer</strong> â†’ multi-agent, reasoning-based retrieval that packs only the facts that matter</li>
      <li><strong>Lifecycle Management</strong> â†’ facts are versioned, updated, and conflict-resolved automatically</li>
      <li><strong>Autonomous CoT Orchestration</strong> â†’ self-directed reasoning â†’ fewer tokens, faster replies, higher accuracy</li>
      <li><strong>Data Governance</strong> â†’ white-box by design â€” full traceability, provenance, and user-level control baked in</li>
    </ul>
  </div>

  <div>
    <h2>ğŸ¯ Use Cases</h2>
    <ul>
      <li><strong>Personal AI</strong> â†’ not memory. Awareness that adapts to you in real time</li>
      <li><strong>Customer Support</strong> â†’ not logs. Clear user story that resolves issues on the first touch</li>
      <li><strong>Healthcare</strong> â†’ not raw data. Connect all the dots for reliable patient profiles â†’ safer adaptive care</li>
      <li><strong>Developer &amp; Creator Copilots</strong> â†’ not autocomplete. Repo + workflow intelligence that guides the next move</li>
    </ul>
    <p>ğŸ¤– <a href="https://api.ontbo.com">https://api.ontbo.com</a></p>
  </div>

  <div>
    <h2>ğŸ— Strategic Benefits (Product &amp; Infra)</h2>
    <ul>
      <li><strong>Product</strong> â†’ sharper, context-aware responses â†’ higher CSAT &amp; conversions</li>
      <li><strong>Infra</strong> â†’ big LLM token savings &amp; lower inference load â†’ measurable cost reductions</li>
      <li><strong>Moat</strong> â†’ fine-grained, context-rich personalization with traceable provenance</li>
      <li><strong>Ops</strong> â†’ faster model creation &amp; iteration (+200%), predictable scaling, fewer cold starts</li>
    </ul>
  </div>

  <div>
    <h2>âš™ï¸ Production Tips</h2>
    <ul>
      <li>Use <strong>low-latency mode</strong> for real-time UIs (P50 â‰ˆ 40 ms)</li>
      <li>Use <strong>best-performance</strong> for async batch jobs where recall matters (â‰ˆ 90% recall)</li>
      <li>Set <strong>max_tokens_context</strong> to control cost â†’ ONTBO prioritizes &amp; compresses context</li>
      <li>Enable <strong>traceability</strong> for regulated/high-stakes outputs (export facts + provenance)</li>
      <li>Monitor <strong>token_cost_saved_pct</strong> &amp; recall per tenant â†’ tune retrieval modes</li>
    </ul>
  </div>

  <div>
    <h2>ğŸ“š Documentation &amp; Support</h2>
    <ul>
      <li><strong>Full docs:</strong> <a href="https://api.ontbo.com/api/tests/docs">https://api.ontbo.com/api/tests/docs</a></li>
      <li><strong>Community:</strong> <a href="https://discord.com/invite/N8h4ZBJb">Discord</a> Â· <a href="https://x.com/ONTBO_AI">X</a></li>
      <li><strong>Contact:</strong> contact@ontbo.com</li>
    </ul>
  </div>

  <div>
    <h2>ğŸ¤ License &amp; Contributions</h2>
    <ul>
      <li><strong>License: </strong><a href="./LICENSE">Apache 2.0</a></li>
      <li><strong>Contributions:</strong> PRs welcome. Open issues for bugs/feature requests</li>
      <li><strong>Security:</strong> responsible disclosure at contact@ontbo.com</li>
    </ul>
  </div>

  <br><p><em>âœ¨ Letâ€™s build something people didnâ€™t think was possible.<br>
  ğŸ”¥ Go break things (and tell us what you build).</em></p>

</body>
</html>
