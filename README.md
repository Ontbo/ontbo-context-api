
![header Ontbo](https://github.com/user-attachments/assets/780ad7c3-2e95-41a7-8459-7cfdd2ce2504)

  <p align="center"><strong>Make AIs understand your users.</strong></p>
  <p align="center">ğŸ‘‰ Cognitive Context API for your AI Agents</p>
  <p align="center">ğŸŒ Homepage:<a href="https://www.ontbo.com">https://www.ontbo.com</a></p>
  <p align="center">ğŸ¤– Developper hub:<a href="https://api.ontbo.com">https://api.ontbo.com</a></p>
  <p align="center">ğŸ“„ Datasheet: <a href="./static/datasheet.pdf">here</a></p>
  <p align="center">Enjoying ONTBO? â­ï¸ us to support the project!</p>

  <div>
    <h2> Introduction </h2>

Ontbo API provides a cognitive context layer for AI agents.
It adds long-term memory, persistent context, and reasoning-driven retrieval, enabling AI systems to deliver highly relevant answers and remain consistent over time.
Ontbo API plugs into any LLM stack and helps teams build reliable, scalable AI systems.

 <p> If your assistants hallucinate, token bills spike, and user context lives in 12 different silos â€“ <strong>ONTBO fixes thatğŸ”¥.</strong></p>
    <p>Plug a <b>cognitive layer</b> in front of your LLMs/Agents and stop duct-taping prompt engineering.<br>
    Your agents become sharper.</p>
    <p><strong>Memory stores. Context understands.</strong></p>
  </div>


  <div>
    <h2>ğŸ§© Main Features</h2>
    <ul>
      <li><strong>Context Layer</strong> â†’ multi-agent, reasoning-based retrieval that packs only the facts that matter</li>
      <li><strong>Lifecycle Management</strong> â†’ facts are versioned, updated, and conflict-resolved automatically</li>
      <li><strong>Autonomous CoT Orchestration</strong> â†’ self-directed reasoning â†’ fewer tokens, faster replies, higher accuracy</li>
      <li><strong>Data Governance</strong> â†’ white-box by design â€” full traceability, provenance, and user-level control baked in</li>
    </ul>
  </div>

<div>
    <h2>ğŸ¯ Use Cases</h2>
    <ul>
      <li><strong>Personal AI</strong> â†’ not memory. Awareness that adapts to you in real time</li>
      <li><strong>Customer Support</strong> â†’ not logs. Clear user story that resolves issues on the first touch</li>
      <li><strong>Healthcare</strong> â†’ not raw data. Connect all the dots for reliable patient profiles â†’ safer adaptive care</li>
      <li><strong>Developer &amp; Creator Copilots</strong> â†’ not autocomplete. Repo + workflow intelligence that guides the next move</li>
    </ul>
  </div>


<h2>ğŸš€ Get started (seriously, 5 min)</h2>

1ï¸âƒ£ Create your account and fetch your api keyâ†’ <a href="https://api.ontbo.com">https://api.ontbo.com</a>

2ï¸âƒ£ Install the lib
```
pip install ontbo
```

3ï¸âƒ£ Your first application in a few lines of code.
```py
from ontbo import Ontbo, SceneMessage

ontbo = Ontbo(token="<YOU_API_KEY_HERE>")
profile = ontbo.create_profile("alice_test")
scene = profile.create_scene("scene_test")

scene.add_messages(
  [SceneMessage(content="Hello, my name is Alice!")], 
  update_now=True)

print(profile.query_facts("What the user's name?"))
```

  <p>ğŸ’¡ Not using Python? See directly our Web API reference â†’ <a href="https://api.ontbo.com/api/tests/docs">https://api.ontbo.com/api/tests/docs</a></p>
  </div>

<h2> ğŸ¤– Why Ontbo? </h2>

The biggest bottleneck for AI agents isn't the modelâ€”it's the **context**. 
Stop duct-taping prompt engineering and messy RAG pipelines. Ontbo provides a specialized **Cognitive Context API** that acts as a sophisticated memory layer for your LLMs.

* **ğŸ“‰ Cut Token Waste:** Don't resend the same facts. Ontbo optimizes what goes into the prompt.
* **ğŸš« Kill Hallucinations:** Ground your agent with verified, retrieved facts in real-time.
* **ğŸ§  Human-like Memory:** Manage complex user histories and cross-session knowledge effortlessly.
* **âš¡ Dev-First:** Integrates with your existing stack in minutes.

  <div>
    <h2>âš¡ Research Insights - Why you Win ?</h2>
    <table>
      <tr>
        <th><i>Metric</i></th>
        <th><i>ONTBO</i></th>
        <th><i>SoTA</i></th>
      </tr>
      <tr>
        <td><i>Recall context</i></td>
        <td><b>ğŸ”¥ 91%</b></td>
        <td>70%</td>
      </tr>
      <tr>
        <td><i>Token cost</i></td>
        <td><b>ğŸ’¸ -95%</b></td>
        <td>Full-data retrieval</td>
      </tr>
      <tr>
        <td><i>Latency</i></td>
        <td><b>âš¡ 40 ms (P50)</b></td>
        <td>&gt;200 ms</td>
      </tr>
      <tr>
        <td><i>Model creation speed</i></td>
        <td><b>ğŸš€ +200%</b></td>
        <td>Baseline</td>
      </tr>
    </table>
    <p>ğŸ”„ <b>4 retrieval modes</b>: best-performance, chain-of-thought, balanced, low-latency<br>
    âœ”ï¸ pick precision/latency/cost tradeoffs per request</p>
  </div>

---
  
## âš¡ï¸ Performance Showcase: ChatGPT 5.2 x Ontbo API

Context fragmentation is the silent killer of AI efficiency. See how Ontbo transforms a standard LLM interaction by providing a sophisticated cognitive memory layer.

### ğŸ¬ Comparative Demo
[![Watch the Demo](https://img.youtube.com/vi/e0uITdv5xlc/maxresdefault.jpg)](https://www.youtube.com/watch?v=e0uITdv5xlc)

| Feature | ChatGPT (5.2 thinking) | ChatGPT + Ontbo API |
| :--- | :--- | :--- |
| **Context Retention** | Limited / "Forgetful" | **Persistent & Cognitive** |
| **Retrieval Accuracy** | Basic RAG (Messy) | **Specialized Memory Layer** |
| **Logic Consistency** | Dribbles over long sessions | **Maintains High-Fidelity Logic** |

> **Key Takeaway:** While standard models struggle with "duct-taped" prompt engineering, Ontbo ensures your agent actually *understands* the historical context of the conversation.

<div>
    <h2>ğŸ— Strategic Benefits (Product &amp; Infra)</h2>
    <ul>
      <li><strong>Product</strong> â†’ sharper, context-aware responses â†’ higher CSAT &amp; conversions</li>
      <li><strong>Infra</strong> â†’ big LLM token savings &amp; lower inference load â†’ measurable cost reductions</li>
      <li><strong>Moat</strong> â†’ fine-grained, context-rich personalization with traceable provenance</li>
      <li><strong>Ops</strong> â†’ faster model creation &amp; iteration (+200%), predictable scaling, fewer cold starts</li>
    </ul>
  </div>

<img width="3509" height="2481" alt="Benchmark Ontbo_2026" src="https://github.com/user-attachments/assets/27301fb8-7834-4dba-af52-098824243db5" />
 <p> This is not merely another vendor-biased benchmark. This performance analysis, comparing ChatGPT 5.2 without Ontbo API and ChatGPT 5.2 with Ontbo API, follows a rigorous methodology formally validated by the Cambridge University Scientific Board in December 2025. Based on 19 items (demographics, cognition, health, financesâ€¦).
Performance was measured across more than 500 multi-turn conversations, comparing intrinsic hashtag#LLM memory with an external conversational memory layer.

â¡ï¸ This benchmark shows what happens when an external cognitive context layer works alongside leading models, with long-term reasoning reaching up to 93% recall accuracy. 
â¡ï¸ Itâ€™s not a RAG, not memory tools, not a buffer. <p>

  <div>
    <h2>ğŸ“š Documentation &amp; Support</h2>
    <ul>
      <li><strong>API reference docs:</strong> <a href="https://api.ontbo.com/api/tests/docs">https://api.ontbo.com/api/tests/docs</a></li>
      <li><strong>Community:</strong> <a href="https://discord.com/invite/N8h4ZBJb">Discord</a> Â· <a href="https://x.com/ONTBO_AI">X</a></li>
      <li><strong>Contact:</strong> <a href="mailto:contact@ontbo.com">contact@ontbo.com</a></li>
    </ul>
  </div>

  <div>
    <h2>ğŸ¤ License &amp; Contributions</h2>
    <ul>
      <li><strong>License: </strong><a href="./LICENSE">Apache 2.0</a></li>
      <li><strong>Contributions:</strong> PRs welcome. Open issues for bugs/feature requests</li>
      <li><strong>Security:</strong> responsible disclosure at contact@ontbo.com</li>
    </ul>
  </div>

  <br><p>âœ¨ Letâ€™s build something people didnâ€™t think was possible.<br>
  ğŸ”¥ Go break things (and tell us what you build).</p>


<b>If you find this useful, please give us a â­ to help others find us!</b>
</p>

</body>
</html>























